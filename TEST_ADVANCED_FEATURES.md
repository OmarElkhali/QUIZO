# ğŸ§ª GUIDE DE TEST - AMÃ‰LIORATIONS GROQ

**Version**: 2.1  
**Date**: 23 Novembre 2025

---

## ğŸ“‹ CHECKLIST DE TEST

### âœ… 1. Retry Automatique

**Test**: Simuler erreur rÃ©seau temporaire

**MÃ©thode**:
```powershell
# Terminal 1: DÃ©marrer backend
cd python_api
python app.py

# Terminal 2: Test avec interruption rÃ©seau
# Pendant la gÃ©nÃ©ration, dÃ©sactiver/rÃ©activer WiFi briÃ¨vement
```

**RÃ©sultat Attendu**:
```
ğŸ”„ Attempt 1/3...
âš ï¸ Attempt 1 failed: Connection error
â³ Retrying in 1.0s...
ğŸ”„ Attempt 2/3...
âœ… Generation completed in 8.5s
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] Retry automatique dÃ©clenchÃ©
- [ ] DÃ©lai croissant (1s, 2s, 4s)
- [ ] GÃ©nÃ©ration complÃ¨te aprÃ¨s retry

---

### âœ… 2. DÃ©tection de Duplicatas

**Test**: Forcer gÃ©nÃ©ration avec texte court

**Commande**:
```typescript
const text = "Python est un langage. Python est populaire.";

const questions = await generateQuestionsWithGroq(text, {
  numQuestions: 10,
  model: 'llama-3.3-70b-versatile'
});
```

**RÃ©sultat Attendu (Backend)**:
```
ğŸ” Found 2 duplicate questions, filtering...
âœ… 8/10 questions generated successfully (2 duplicates removed)
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] Duplicatas dÃ©tectÃ©s dans les logs
- [ ] Questions filtrÃ©es automatiquement
- [ ] Log indique nombre de duplicatas

---

### âœ… 3. Cache In-Memory

**Test**: RequÃªte identique 2 fois

**Commande**:
```typescript
// Appel 1
console.time('Premier appel');
const q1 = await generateQuestionsWithGroq(text, { numQuestions: 5 });
console.timeEnd('Premier appel');

// Appel 2 (identique)
console.time('DeuxiÃ¨me appel (cache)');
const q2 = await generateQuestionsWithGroq(text, { numQuestions: 5 });
console.timeEnd('DeuxiÃ¨me appel (cache)');
```

**RÃ©sultat Attendu**:
```
Premier appel: 3542ms
ğŸ’¾ Questions rÃ©cupÃ©rÃ©es du cache (Ã©conomie de temps et requÃªtes)
DeuxiÃ¨me appel (cache): 2ms
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] Premier appel: 3-10s
- [ ] DeuxiÃ¨me appel: <10ms
- [ ] Message cache affichÃ©
- [ ] Questions identiques

---

### âœ… 4. MÃ©triques de Performance

**Test**: GÃ©nÃ©rer plusieurs quiz et afficher stats

**Commande**:
```typescript
import { getGroqMetrics, resetGroqMetrics } from '@/services/groqService';

resetGroqMetrics();

// GÃ©nÃ©rer 3 quiz
await generateQuestionsWithGroq(text1, { numQuestions: 5 });
await generateQuestionsWithGroq(text2, { numQuestions: 10 });
await generateQuestionsWithGroq(text1, { numQuestions: 5 }); // Cache hit

const metrics = getGroqMetrics();
console.log('ğŸ“Š MÃ©triques:', metrics);
```

**RÃ©sultat Attendu**:
```json
{
  "totalRequests": 3,
  "successfulRequests": 3,
  "failedRequests": 0,
  "averageResponseTime": 4230.5,
  "cacheHits": 1
}
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] totalRequests = 3
- [ ] cacheHits = 1 (troisiÃ¨me appel)
- [ ] averageResponseTime < 10000ms
- [ ] failedRequests = 0

---

### âœ… 5. Fallback Intelligent

**Test**: Timeout avec suggestion

**MÃ©thode**: Demander trop de questions pour dÃ©clencher timeout

**Commande**:
```typescript
try {
  // Forcer timeout (mock ou vraie limite)
  await generateQuestionsWithGroq(longText, {
    numQuestions: 100,  // Trop pour un seul appel
    model: 'llama-3.3-70b-versatile'
  });
} catch (error) {
  console.log('Erreur:', error.message);
}
```

**RÃ©sultat Attendu**:
```
ğŸ’¡ Suggestion: Essayez le modÃ¨le llama-3.1-8b-instant (plus rapide)
Timeout Groq aprÃ¨s 100 questions. RÃ©duisez le nombre ou utilisez llama-3.1-8b-instant.
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] Message d'erreur explicite
- [ ] Suggestion de modÃ¨le alternatif
- [ ] Conseil actionnable

---

### âœ… 6. Tokens Adaptatifs

**Test**: VÃ©rifier logs backend pour diffÃ©rents volumes

**Commandes**:
```python
# Test 1: 5 questions
service.generate_quiz(text, num_questions=5)

# Test 2: 20 questions
service.generate_quiz(text, num_questions=20)

# Test 3: 40 questions
service.generate_quiz(text, num_questions=40)
```

**RÃ©sultat Attendu (Backend)**:
```
# Test 1
ğŸ“Š Token estimation: 5 questions â†’ 4096 max_tokens

# Test 2
ğŸ“Š Token estimation: 20 questions â†’ 6000 max_tokens

# Test 3
ğŸ“Š Token estimation: 40 questions â†’ 8192 max_tokens (limite)
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] 5 questions â†’ 4096 tokens
- [ ] 20 questions â†’ 6000 tokens
- [ ] 40 questions â†’ 8192 tokens (plafonnÃ©)
- [ ] Toutes les questions gÃ©nÃ©rÃ©es

---

### âœ… 7. Prompt OptimisÃ© (100% Questions)

**Test**: Demander exactement 30 questions

**Commande**:
```python
questions = service.generate_quiz(
    text=long_text,
    num_questions=30,
    difficulty="medium"
)
print(f"GÃ©nÃ©rÃ©: {len(questions)}/30")
```

**RÃ©sultat Attendu**:
```
ğŸš€ Generating 30 questions with Groq (llama-3.3-70b-versatile)...
ğŸ“Š Token estimation: 30 questions â†’ 8192 max_tokens
âš¡ Generation completed in 9.23s
âœ… 30/30 questions generated successfully
ğŸ“Š Metrics: 100.0% valid, 3.2 q/s
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] 30/30 questions gÃ©nÃ©rÃ©es
- [ ] Aucun avertissement "manque X questions"
- [ ] Temps < 15s
- [ ] Taux de validation 100%

---

## ğŸ”¬ TESTS D'INTÃ‰GRATION

### Test A: Workflow Complet

```typescript
import { 
  generateQuestionsWithGroq, 
  clearGroqCache, 
  getGroqMetrics,
  resetGroqMetrics 
} from '@/services/groqService';

async function testWorkflow() {
  console.log('ğŸ§ª Test Workflow Complet');
  
  resetGroqMetrics();
  clearGroqCache();
  
  const text = `
    Python est un langage de programmation crÃ©Ã© en 1991 par Guido van Rossum.
    Il est connu pour sa syntaxe claire et sa grande communautÃ©.
    Python est utilisÃ© dans le web, la data science, l'IA et l'automatisation.
  `;
  
  // Ã‰tape 1: PremiÃ¨re gÃ©nÃ©ration
  console.log('\nğŸ“ Ã‰tape 1: PremiÃ¨re gÃ©nÃ©ration (5 questions)');
  const start1 = Date.now();
  const q1 = await generateQuestionsWithGroq(text, { 
    numQuestions: 5,
    model: 'llama-3.3-70b-versatile'
  });
  console.log(`âœ… DurÃ©e: ${Date.now() - start1}ms`);
  console.log(`âœ… Questions: ${q1.length}`);
  
  // Ã‰tape 2: Cache hit
  console.log('\nğŸ’¾ Ã‰tape 2: MÃªme requÃªte (cache)');
  const start2 = Date.now();
  const q2 = await generateQuestionsWithGroq(text, { 
    numQuestions: 5,
    model: 'llama-3.3-70b-versatile'
  });
  console.log(`âœ… DurÃ©e: ${Date.now() - start2}ms (devrait Ãªtre <10ms)`);
  
  // Ã‰tape 3: Gros volume
  console.log('\nğŸ“¦ Ã‰tape 3: Gros volume (30 questions)');
  const start3 = Date.now();
  const q3 = await generateQuestionsWithGroq(text, { 
    numQuestions: 30,
    model: 'llama-3.3-70b-versatile'
  });
  console.log(`âœ… DurÃ©e: ${Date.now() - start3}ms`);
  console.log(`âœ… Questions: ${q3.length}/30`);
  
  // MÃ©triques finales
  console.log('\nğŸ“Š MÃ©triques Finales:');
  const metrics = getGroqMetrics();
  console.log(JSON.stringify(metrics, null, 2));
  
  // Assertions
  console.log('\nâœ… VÃ‰RIFICATIONS:');
  console.assert(q1.length === 5, 'âŒ Ã‰tape 1: 5 questions attendues');
  console.assert(q2.length === 5, 'âŒ Ã‰tape 2: 5 questions attendues (cache)');
  console.assert(q3.length >= 28, 'âŒ Ã‰tape 3: Minimum 28/30 questions');
  console.assert(metrics.cacheHits === 1, 'âŒ 1 cache hit attendu');
  console.assert(metrics.successfulRequests === 3, 'âŒ 3 succÃ¨s attendus');
  
  console.log('\nğŸ‰ Workflow complet rÃ©ussi!');
}

testWorkflow();
```

**RÃ©sultat Attendu**:
```
ğŸ§ª Test Workflow Complet

ğŸ“ Ã‰tape 1: PremiÃ¨re gÃ©nÃ©ration (5 questions)
âœ… DurÃ©e: 3542ms
âœ… Questions: 5

ğŸ’¾ Ã‰tape 2: MÃªme requÃªte (cache)
ğŸ’¾ Questions rÃ©cupÃ©rÃ©es du cache (Ã©conomie de temps et requÃªtes)
âœ… DurÃ©e: 3ms (devrait Ãªtre <10ms)

ğŸ“¦ Ã‰tape 3: Gros volume (30 questions)
âœ… DurÃ©e: 9234ms
âœ… Questions: 30/30

ğŸ“Š MÃ©triques Finales:
{
  "totalRequests": 3,
  "successfulRequests": 3,
  "failedRequests": 0,
  "averageResponseTime": 4259.33,
  "cacheHits": 1
}

âœ… VÃ‰RIFICATIONS:
âœ… Ã‰tape 1: OK
âœ… Ã‰tape 2: OK (cache)
âœ… Ã‰tape 3: OK (30/30)
âœ… Cache hits: OK
âœ… SuccÃ¨s: OK

ğŸ‰ Workflow complet rÃ©ussi!
```

---

## ğŸ¯ TESTS DE CHARGE

### Test Performance: 50 Questions

```typescript
async function testPerformance() {
  const longText = `...texte de 5000 mots...`;
  
  console.time('50 questions');
  const questions = await generateQuestionsWithGroq(longText, {
    numQuestions: 50,
    model: 'llama-3.3-70b-versatile'
  });
  console.timeEnd('50 questions');
  
  console.log(`GÃ©nÃ©rÃ©: ${questions.length}/50`);
  console.log(`Temps par question: ${(performance.now() / questions.length).toFixed(0)}ms`);
}
```

**CritÃ¨res de SuccÃ¨s**:
- [ ] â‰¥ 45/50 questions gÃ©nÃ©rÃ©es (90%)
- [ ] Temps total < 20s
- [ ] Pas d'erreur critique

---

## ğŸ› TESTS D'ERREUR

### Test 1: API Key Invalide

```python
# Modifier temporairement .env
GROQ_API_KEY=invalid_key_xyz

# Relancer backend
python app.py
```

**RÃ©sultat Attendu**:
```
âŒ Authentication error, no retry
ValueError: GROQ_API_KEY invalid
```

### Test 2: ModÃ¨le Inexistant

```typescript
await generateQuestionsWithGroq(text, {
  model: 'fake-model-xyz'
});
```

**RÃ©sultat Attendu**:
```
âŒ Invalid model, no retry
ModÃ¨le Groq obsolÃ¨te. Utilisez: llama-3.3-70b-versatile, llama-3.1-8b-instant...
```

### Test 3: Texte Trop Court

```typescript
await generateQuestionsWithGroq('Python', { numQuestions: 5 });
```

**RÃ©sultat Attendu**:
```
âŒ Le texte source doit contenir au moins 50 caractÃ¨res
```

---

## ğŸ“Š RAPPORT DE TEST

### Template

```markdown
# Rapport de Test - AmÃ©liorations Groq
Date: __________
Testeur: __________

## Tests Fonctionnels
- [ ] Retry automatique
- [ ] DÃ©tection duplicatas
- [ ] Cache in-memory
- [ ] MÃ©triques performance
- [ ] Fallback intelligent
- [ ] Tokens adaptatifs
- [ ] Prompt optimisÃ©

## Tests d'IntÃ©gration
- [ ] Workflow complet
- [ ] 50 questions
- [ ] Erreurs gÃ©rÃ©es

## MÃ©triques Finales
- Taux de succÃ¨s: ____%
- Taux de cache: ____%
- Temps moyen: ____s

## ProblÃ¨mes RencontrÃ©s
1. _________
2. _________

## Recommandations
- _________
- _________
```

---

## ğŸš€ COMMANDES RAPIDES

### Reset Complet

```powershell
# Backend
cd python_api
rm -rf __pycache__
python app.py

# Frontend
npm run dev
# Dans console navigateur:
clearGroqCache()
resetGroqMetrics()
```

### Monitoring Live

```typescript
// Ajouter dans DevTools Console
setInterval(() => {
  const m = getGroqMetrics();
  console.log(`ğŸ“Š ${m.successfulRequests}/${m.totalRequests} | Cache: ${m.cacheHits} | Avg: ${(m.averageResponseTime/1000).toFixed(1)}s`);
}, 5000);
```

---

## âœ… VALIDATION FINALE

Tous les tests passent si:
1. âœ… Retry fonctionne (logs visibles)
2. âœ… Duplicatas dÃ©tectÃ©s (>0 dans logs)
3. âœ… Cache fonctionne (<10ms deuxiÃ¨me appel)
4. âœ… MÃ©triques correctes
5. âœ… Fallback suggÃ¨re alternatives
6. âœ… Tokens adaptatifs (logs backend)
7. âœ… 30/30 questions gÃ©nÃ©rÃ©es

**Status**: ğŸ‰ PRODUCTION READY
