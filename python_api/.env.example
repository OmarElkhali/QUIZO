# Configuration Flask
FLASK_APP=app.py
FLASK_ENV=development
FLASK_DEBUG=1
LOG_LEVEL=INFO

# Clés API IA (OPTIONNELLES si vous utilisez Ollama/LLM local)
# Groq (RECOMMANDÉ - Ultra-rapide, GRATUIT, 14,400 req/jour)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Configuration avancée Groq
GROQ_MAX_RETRIES=3
GROQ_RETRY_DELAY=1.0

# Alternatives
GEMINI_API_KEY=your_gemini_api_key_here
CHATGPT_API_KEY=your_openai_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Configuration Ollama (LLM Local - GRATUIT et PRIVÉ)
# Pour utiliser des modèles open-source comme Qwen, Llama, Mistral
# Installation : https://ollama.com/download
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b

# Modèles recommandés pour QUIZO :
#   - qwen2.5:7b (recommandé - excellent français, 4.7 GB)
#   - llama3.1:8b (très bon multilingue, 5 GB)
#   - mistral:7b (rapide et performant en français, 4.1 GB)
#   - phi3:mini (léger pour PC modestes, 2.3 GB)
#   - qwen2.5:14b (meilleure qualité si bon GPU, 8.5 GB)

# Configuration CORS (liste séparée par des virgules)
CORS_ORIGINS=http://localhost:5173,http://localhost:8080,https://your-production-domain.com
